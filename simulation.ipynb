{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from PSSimPy.simulator import ABMSim\n",
    "from PSSimPy import Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Strategic Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Intrady Liquidity Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state: s = (t, b, β, ω, E)\n",
    "MDPState = namedtuple(\"MDPState\", [\n",
    "    \"t\", \n",
    "    \"balance\", \n",
    "    \"borrowed\", \n",
    "    \"obligations\", \n",
    "    \"expected_inbound\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OriMDPSearch:\n",
    "    \"\"\"\n",
    "    MDP formulation for the focal player's decision in an n-player Intraday Liquidity Game.\n",
    "    \n",
    "    State: s = (t, b, β, ω, E), where:\n",
    "      - t: current period,\n",
    "      - b: focal player's balance,\n",
    "      - β: focal player's borrowed amount,\n",
    "      - ω: focal player's outstanding obligations,\n",
    "      - E: aggregate expected inbound payment from the n-1 opponents, \n",
    "           given by E_t = (n-1)p_tz^*.\n",
    "    \n",
    "    Here, p_t is the probability that an obligation arises (per opponent) in period t.\n",
    "    If an obligation arises, opponents pay the focal player if their dominant strategy is to pay,\n",
    "    which (with tie → pay) implies z^* = 1 when γ ≤ δ, and 0 when γ > δ.\n",
    "    Under pure rational expectations (i.e., with ζ = 0), agents do not update their expectations.\n",
    "    \n",
    "    The focal player has two strategies:\n",
    "      0 = Delay: incur delay cost δ per unit of obligation; obligations carry forward.\n",
    "      1 = Pay: if b < ω, borrow the shortfall at cost γ per unit; clear obligations;\n",
    "           any excess balance repays borrowing.\n",
    "           \n",
    "    The focal player also pays a carry cost of γ·β each period.\n",
    "    \n",
    "    We solve the MDP via depth-limited dynamic programming, reflecting bounded rationality.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_players=4,\n",
    "                 n_periods=4, \n",
    "                 p_t=0.8,      # probability an obligation arises per opponent in a period\n",
    "                 delta=0.2, \n",
    "                 gamma=0.1,\n",
    "                 zeta=0.0,     # learning rate, set to 0 for pure RE\n",
    "                 seed=42):\n",
    "        \"\"\"\n",
    "        n_players   : total players (focal + opponents)\n",
    "        n_periods   : horizon for the MDP\n",
    "        p_t         : probability an obligation arises per opponent\n",
    "        delta       : per-unit delay cost\n",
    "        gamma       : cost for borrowing and carrying borrowed funds\n",
    "        zeta        : learning rate for updating expectations (set to 0 for pure RE)\n",
    "        seed        : random seed for reproducibility\n",
    "        \"\"\"\n",
    "        random.seed(seed)\n",
    "        self.n_players = n_players\n",
    "        self.n_periods = n_periods\n",
    "        self.p_t = p_t\n",
    "        self.delta = delta\n",
    "        self.gamma = gamma\n",
    "        self.zeta = zeta  # with zeta=0, no updating occurs\n",
    "        # Dominant strategy assumption: if γ ≤ δ then opponents pay, i.e., z^*=1; otherwise, z^*=0.\n",
    "        self.z_star = 1.0 if self.gamma <= self.delta else 0.0\n",
    "\n",
    "    def initial_state(self):\n",
    "        \"\"\"\n",
    "        The initial state: the focal player's balance, borrowed, and obligations are zero.\n",
    "        The initial aggregate expected inbound is:\n",
    "           E₀ = (n_players - 1) * p_t * z_star.\n",
    "        \"\"\"\n",
    "        E0 = (self.n_players - 1) * self.p_t * self.z_star\n",
    "        return MDPState(\n",
    "            t=0,\n",
    "            balance=0.0,\n",
    "            borrowed=0.0,\n",
    "            obligations=0.0,\n",
    "            expected_inbound=E0\n",
    "        )\n",
    "\n",
    "    def carry_cost(self, borrowed):\n",
    "        \"\"\"Cost for carrying borrowed funds over one period.\"\"\"\n",
    "        return self.gamma * borrowed if borrowed > 0 else 0.0\n",
    "\n",
    "    def transition_function(self, state, action):\n",
    "        \"\"\"\n",
    "        Given state s = (t, b, β, ω, E) and focal action a ∈ {0,1},\n",
    "        return a list of (next_state, probability, immediate_cost).\n",
    "        \n",
    "        Here, we assume that in each period, every opponent independently generates an obligation \n",
    "        with probability p_t, so that on average, (n_players - 1)*p_t obligations arrive.\n",
    "        For simplicity, we assume that the number of new obligations is exactly (n-1)p_t.\n",
    "        \n",
    "        The focal player's balance is increased by the aggregate expected inbound E,\n",
    "        and then the chosen action is applied:\n",
    "         - If a = 1 (Pay): if b + E < ω + (n-1)p_t, the focal borrows the shortfall (cost = γ*(shortfall)); \n",
    "           obligations clear.\n",
    "         - If a = 0 (Delay): cost = δ times the total obligations.\n",
    "        In both cases, a carry cost γβ is added.\n",
    "        \"\"\"\n",
    "        if state.t >= self.n_periods:\n",
    "            return [(state, 1.0, 0.0)]\n",
    "        \n",
    "        # Compute carry cost\n",
    "        cost_carry = self.carry_cost(state.borrowed)\n",
    "        # Inbound: focal's balance increases by E\n",
    "        mid_balance = state.balance + state.expected_inbound\n",
    "        # New obligations: exactly (n-1)p_t arrive\n",
    "        new_arrivals = (self.n_players - 1) * self.p_t\n",
    "        new_oblig = state.obligations + new_arrivals\n",
    "\n",
    "        if action == 1:  # Pay\n",
    "            shortfall = max(0.0, new_oblig - mid_balance)\n",
    "            cost_borrow = self.gamma * shortfall if shortfall > 0 else 0.0\n",
    "\n",
    "            new_balance = mid_balance\n",
    "            new_borrowed = state.borrowed\n",
    "            if shortfall > 0:\n",
    "                new_balance = 0.0\n",
    "                new_borrowed += shortfall\n",
    "                new_oblig_after = 0.0\n",
    "            else:\n",
    "                new_balance = mid_balance - new_oblig\n",
    "                new_oblig_after = 0.0\n",
    "\n",
    "            if new_balance > 0 and new_borrowed > 0:\n",
    "                repay = min(new_balance, new_borrowed)\n",
    "                new_borrowed -= repay\n",
    "                new_balance -= repay\n",
    "\n",
    "            immediate_cost = cost_carry + cost_borrow\n",
    "            next_state = MDPState(\n",
    "                t=state.t + 1,\n",
    "                balance=new_balance,\n",
    "                borrowed=new_borrowed,\n",
    "                obligations=new_oblig_after,\n",
    "                expected_inbound=state.expected_inbound  # under pure RE, remains constant\n",
    "            )\n",
    "            return [(next_state, 1.0, immediate_cost)]\n",
    "        else:  # Delay\n",
    "            cost_delay = self.delta * new_oblig\n",
    "            immediate_cost = cost_carry + cost_delay\n",
    "            next_state = MDPState(\n",
    "                t=state.t + 1,\n",
    "                balance=mid_balance,\n",
    "                borrowed=state.borrowed,\n",
    "                obligations=new_oblig,\n",
    "                expected_inbound=state.expected_inbound\n",
    "            )\n",
    "            return [(next_state, 1.0, immediate_cost)]\n",
    "\n",
    "    def actions(self, state):\n",
    "        \"\"\"Return the focal player's actions: 0 = Delay, 1 = Pay.\"\"\"\n",
    "        return [0, 1]\n",
    "\n",
    "    def state_to_key(self, state):\n",
    "        \"\"\"Convert state into a hashable tuple for memoization.\"\"\"\n",
    "        return (state.t, round(state.balance,4), round(state.borrowed,4),\n",
    "                round(state.obligations,4), round(state.expected_inbound,4))\n",
    "\n",
    "    def depth_limited_value(self, state, depth, memo=None):\n",
    "        \"\"\"\n",
    "        Depth-limited lookahead from state up to 'depth' periods.\n",
    "        Returns (best_value, best_action) where best_value is the maximum expected reward \n",
    "        (i.e., negative total cost) and best_action ∈ {0,1}.\n",
    "        \n",
    "        This recursive algorithm uses memoization. The limited depth represents the \n",
    "        bounded rationality of the focal player in forming its rational expectation.\n",
    "        \"\"\"\n",
    "        if memo is None:\n",
    "            memo = {}\n",
    "        if depth <= 0 or state.t >= self.n_periods:\n",
    "            return (0.0, None)\n",
    "        key = (self.state_to_key(state), depth)\n",
    "        if key in memo:\n",
    "            return memo[key]\n",
    "        best_value = float('-inf')\n",
    "        best_action = None\n",
    "        for a in self.actions(state):\n",
    "            transitions = self.transition_function(state, a)\n",
    "            total_val = 0.0\n",
    "            for (ns, prob, cost) in transitions:\n",
    "                immediate_reward = -cost  # cost is a negative reward\n",
    "                future_val, _ = self.depth_limited_value(ns, depth - 1, memo)\n",
    "                total_val += prob * (immediate_reward + future_val)\n",
    "            if total_val > best_value:\n",
    "                best_value = total_val\n",
    "                best_action = a\n",
    "        memo[key] = (best_value, best_action)\n",
    "        return memo[key]\n",
    "\n",
    "    def update_current_state(self, current_state, focal_action, partial_observations):\n",
    "        \"\"\"\n",
    "        Update the current state based on the focal player's chosen action and partial observations.\n",
    "        \n",
    "        partial_observations is a dictionary containing:\n",
    "          - \"inbound_payments\": actual inbound payment received,\n",
    "          - \"arrived_obligations\": number of new obligations that actually arrived,\n",
    "          - \"observed_expected\": observed aggregate inbound (e.g., from opponents).\n",
    "        \n",
    "        Under our pure rational expectations assumption (with ζ = 0), the aggregate expectation\n",
    "        remains fixed as E_t = (n-1)p_tz^*. However, to allow for potential deviations, we include \n",
    "        an update rule:\n",
    "        \n",
    "          E' = ζ · (observed_expected) + (1 - ζ) · E.\n",
    "          \n",
    "        Setting ζ = 0 recovers the pure RE case.\n",
    "        \n",
    "        Returns the updated state s' = (t+1, b', β', ω', E').\n",
    "        \"\"\"\n",
    "        observed_inbound = partial_observations.get(\"inbound_payments\", 0.0)\n",
    "        new_balance_pre = current_state.balance + observed_inbound\n",
    "        arrived = partial_observations.get(\"arrived_obligations\", 0)\n",
    "        new_obligations = current_state.obligations + arrived\n",
    "        observed_expected = partial_observations.get(\"observed_expected\", current_state.expected_inbound)\n",
    "        new_expected = self.zeta * observed_expected + (1 - self.zeta) * current_state.expected_inbound\n",
    "\n",
    "        if focal_action == 1:  # Pay\n",
    "            shortfall = max(0.0, new_obligations - new_balance_pre)\n",
    "            new_borrowed = current_state.borrowed + shortfall\n",
    "            if shortfall > 0:\n",
    "                new_balance = 0.0\n",
    "                new_oblig_after = 0.0\n",
    "            else:\n",
    "                new_balance = new_balance_pre - new_obligations\n",
    "                new_oblig_after = 0.0\n",
    "            if new_balance > 0 and new_borrowed > 0:\n",
    "                repay = min(new_balance, new_borrowed)\n",
    "                new_borrowed -= repay\n",
    "                new_balance -= repay\n",
    "            next_state = MDPState(\n",
    "                t=current_state.t + 1,\n",
    "                balance=new_balance,\n",
    "                borrowed=new_borrowed,\n",
    "                obligations=new_oblig_after,\n",
    "                expected_inbound=new_expected\n",
    "            )\n",
    "            return next_state\n",
    "        else:  # Delay\n",
    "            next_state = MDPState(\n",
    "                t=current_state.t + 1,\n",
    "                balance=new_balance_pre,\n",
    "                borrowed=current_state.borrowed,\n",
    "                obligations=new_obligations,\n",
    "                expected_inbound=new_expected\n",
    "            )\n",
    "            return next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state: MDPState(t=0, balance=0.0, borrowed=0.0, obligations=0.0, expected_inbound=7.2)\n",
      "Best value = 0.00, best action = PAY\n",
      "Updated state after partial observations and chosen action: MDPState(t=1, balance=0.0, borrowed=1.0, obligations=0.0, expected_inbound=7.2)\n",
      "Best value = 0.00, best action = PAY\n",
      "Updated state after partial observations and chosen action: MDPState(t=1, balance=0.0, borrowed=0.0, obligations=0.0, expected_inbound=7.2)\n",
      "Best value = 0.00, best action = PAY\n",
      "Updated state after partial observations and chosen action: MDPState(t=1, balance=0.0, borrowed=1.0, obligations=0.0, expected_inbound=7.2)\n",
      "Best value = 0.00, best action = PAY\n",
      "Updated state after partial observations and chosen action: MDPState(t=1, balance=1.0, borrowed=0.0, obligations=0.0, expected_inbound=7.2)\n",
      "Best value = 0.00, best action = PAY\n",
      "Updated state after partial observations and chosen action: MDPState(t=1, balance=0.0, borrowed=0.0, obligations=0.0, expected_inbound=7.2)\n",
      "Best value = 0.00, best action = PAY\n",
      "Updated state after partial observations and chosen action: MDPState(t=1, balance=0.0, borrowed=1.0, obligations=0.0, expected_inbound=7.2)\n",
      "Best value = 0.00, best action = PAY\n",
      "Updated state after partial observations and chosen action: MDPState(t=1, balance=0.0, borrowed=4.0, obligations=0.0, expected_inbound=7.2)\n",
      "Best value = 0.00, best action = PAY\n",
      "Updated state after partial observations and chosen action: MDPState(t=1, balance=0.0, borrowed=4.0, obligations=0.0, expected_inbound=7.2)\n",
      "Best value = 0.00, best action = PAY\n",
      "Updated state after partial observations and chosen action: MDPState(t=1, balance=0.0, borrowed=1.0, obligations=0.0, expected_inbound=7.2)\n",
      "Best value = 0.00, best action = PAY\n",
      "Updated state after partial observations and chosen action: MDPState(t=1, balance=0.0, borrowed=2.0, obligations=0.0, expected_inbound=7.2)\n"
     ]
    }
   ],
   "source": [
    "# Smoke test\n",
    "n_periods = 10\n",
    "n_players = 10\n",
    "p_t = 0.8\n",
    "mdp = OriMDPSearch(\n",
    "    n_players=n_players,\n",
    "    n_periods=n_periods,\n",
    "    p_t=p_t,\n",
    "    delta=0.3,\n",
    "    gamma=0.25,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "init_state = mdp.initial_state()\n",
    "print(\"Initial state:\", init_state)\n",
    "\n",
    "while n_periods > 0:\n",
    "    best_val, best_act = mdp.depth_limited_value(init_state, depth=n_periods)\n",
    "    print(f\"Best value = {best_val:.2f}, best action = {'DELAY' if best_act==0 else 'PAY'}\")\n",
    "\n",
    "    # actual partial observations\n",
    "    inbound_payments = sum([1 if random.uniform(0.0, 1.0) <= p_t else 0 for _ in range(n_players - 1)])\n",
    "    arrived_obligations = sum([1 if random.uniform(0.0, 1.0) <= p_t else 0 for _ in range(n_players - 1)])\n",
    "    partial_obs = {\n",
    "        \"inbound_payments\": inbound_payments,\n",
    "        \"arrived_obligations\": arrived_obligations,\n",
    "        \"observed_expected\": 0.75 # not important\n",
    "    }\n",
    "\n",
    "    # next state\n",
    "    next_state = mdp.update_current_state(init_state, best_act, partial_obs)\n",
    "    print(\"Updated state after partial observations and chosen action:\", next_state)\n",
    "\n",
    "    n_periods -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up strategic bank agent\n",
    "class OriStrategicBank(Bank):\n",
    "\n",
    "    def __init__(self, name, strategy_type='OriStrategic', **kwargs):\n",
    "        super().__init__(name, strategy_type, **kwargs)\n",
    "    \n",
    "    # overwrite strategy\n",
    "    def strategy(self, txns_to_settle: set, all_outstanding_transactions: set, sim_name: str, day: int, current_time: str, queue) -> set:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intradayliquiditygame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
